{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:29.250445Z",
     "start_time": "2020-02-07T07:32:27.914084Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from time import asctime, strftime\n",
    "\n",
    "import logging\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import String\n",
    "import psycopg2\n",
    "import pysftp\n",
    "import paramiko\n",
    "import io\n",
    "import sys\n",
    "\n",
    "import email\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "####\n",
    "import tpm\n",
    "###\n",
    "cnopts = pysftp.CnOpts()\n",
    "cnopts.hostkeys = None \n",
    "pd.set_option(\"display.max_columns\",99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:29.260856Z",
     "start_time": "2020-02-07T07:32:29.256667Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='LogFile.log',level=logging.DEBUG)\n",
    "LogFileName = 'LogFile.log'\n",
    "logging.basicConfig(filename=LogFileName, level=logging.DEBUG,\n",
    "                    filemode='a', datefmt='%d-%b-%y %H:%M:%S',\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Econda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:45.185714Z",
     "start_time": "2020-02-07T07:32:29.262511Z"
    }
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Let's start with Econda\n",
    "###########################################\n",
    "# \n",
    "# +++ THE NAME OF THE REPORT +++\n",
    "# ReportName\n",
    "# \n",
    "# +++ A TYPICAL REST QUERY +++\n",
    "# https://monitor.econda-monitor.de/rest/chartservice?user=User.Name\n",
    "# &client=1234&pass=xxx&datascope=WEBANALYSIS&GENERATE_TYPE=CSV\n",
    "# &myreport=hexReportName\n",
    "# &fromDate=2018-10-29+00%3A00&toDate=2018-11-05+00%3A00\n",
    "\n",
    "howManyMonths = 3 # hwo many months back?\n",
    "\n",
    "Today = pd.datetime.today()\n",
    "StartDay = pd.datetime.today()-pd.Timedelta(howManyMonths*30,'D')\n",
    "\n",
    "StartDay_string = StartDay.strftime('%Y%m%d')\n",
    "Today_string = Today.strftime('%Y%m%d')\n",
    "\n",
    "StartDay_query = StartDay.strftime('%Y-%m-%d 00:00') # add 00:00 to correctly work with the query\n",
    "Today_query = Today.strftime('%Y-%m-%d 00:00')\n",
    "\n",
    "\n",
    "### starting requests\n",
    "url = 'https://monitor.econda-monitor.de/rest/chartservice' \n",
    "headers = {'user': User.Name, \n",
    "           'client': '1234',\n",
    "           'pass': password, 'datascope':'WEBANALYSIS',\n",
    "           'GENERATE_TYPE':'CSV',\n",
    "           'myreport':'hexReportName','fromDate':StartDay_query,'toDate':Today_query}\n",
    "\n",
    "try:\n",
    "    r = requests.get(url=url, params=headers)\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+'requests: '+r)\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+'oops, problems with requests')\n",
    "try:\n",
    "    #data = pd.read_csv(io.StringIO(r.text),sep=';',decimal=',',encoding='utf_8')\n",
    "    dataEcoRaw = pd.read_csv(io.StringIO(r.text),sep=';',decimal=',',thousands='.',encoding='utf_8', dtype={'Umsatz': 'float'})\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' DataFrame dataEco created')\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+'oops, problems with the datafraem creation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:45.287274Z",
     "start_time": "2020-02-07T07:32:45.187091Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    whichColsEco = ['Newsletter Kampagne','Land','Sprache','Produkte - Stückzahl verkauft',\n",
    "                    'Umsatz','Besuche (unique)','Besucher (unique)','Kunden','Bestellungen',\n",
    "                    'Bounces']\n",
    "    dataEco = dataEcoRaw.loc[:,whichColsEco].rename(columns={'Produkte - Stückzahl verkauft':'Produkte - Stueckzahl verkauft'})\n",
    "\n",
    "    dataEco['Newsletter Kampagne'] = dataEco['Newsletter Kampagne'].str.lower()\n",
    "\n",
    "    # handles the company name: for company3 you find newsletter instead!\n",
    "    dataEco['Firma'] = (dataEco['Newsletter Kampagne']\n",
    "                       .str\n",
    "                        .extract('(^companyName1|^companyName2|^newsletter|^companyName4)',expand=False)\n",
    "                       .replace({'newsletter':'companyName3'}))\n",
    "    \n",
    "    # Salesforce uses sv while econda sv for the swedish laguage. Let's take se for all!\n",
    "    dataEco.Sprache = dataEco.Sprache.replace({'sv':'se'})\n",
    "except Exception:\n",
    "    logging.exception(\"Problems Econda data cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:45.296761Z",
     "start_time": "2020-02-07T07:32:45.288637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Newsletter Kampagne                object\n",
       "Land                               object\n",
       "Sprache                            object\n",
       "Produkte - Stueckzahl verkauft      int64\n",
       "Umsatz                            float64\n",
       "Besuche (unique)                    int64\n",
       "Besucher (unique)                   int64\n",
       "Kunden                              int64\n",
       "Bestellungen                        int64\n",
       "Bounces                             int64\n",
       "Firma                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataEco.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:47.622870Z",
     "start_time": "2020-02-07T07:32:45.316790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Not every companies had the campaign name at the right position. In this way I fix the problem.\n",
    "\n",
    "def MySelection2(x):\n",
    "    try:\n",
    "        return x[2]\n",
    "    except IndexError:\n",
    "        return np.nan\n",
    "\n",
    "def MySelection3(x):\n",
    "    try:\n",
    "        return x[3]\n",
    "    except IndexError:\n",
    "        return np.nan\n",
    "    \n",
    "def MySelection4(x):\n",
    "    try:\n",
    "        return x[4]\n",
    "    except IndexError:\n",
    "        return np.nan\n",
    "\n",
    "try:\n",
    "    dataEco['ThirdField'] = dataEco.loc[:,'Newsletter Kampagne'].str.split(r'%2F|/|//').apply(MySelection2)\n",
    "    dataEco['FourthField'] = dataEco.loc[:,'Newsletter Kampagne'].str.split(r'%2F|/|//').apply(MySelection3) \n",
    "    dataEco['FifthField'] = dataEco.loc[:,'Newsletter Kampagne'].str.split(r'%2F|/|//').apply(MySelection4)\n",
    "\n",
    "    # remove entries for which there is no clear corresponding Campaign name\n",
    "    dataEco = dataEco.loc[(dataEco.FifthField.notnull()) & (dataEco.FourthField.notnull()),:]\n",
    "\n",
    "    # get KampagnenName taking into account the fancy setup of companyName3\n",
    "    dataEco['KampagnenName'] = dataEco.apply(lambda x: x['FifthField'] if x['Firma']=='companyName3' else x['FourthField'],axis=1)\n",
    "\n",
    "    # get Kategorie taking into account the fancy setup of companyName3\n",
    "    # Kategorie is always the field before the KampagenName\n",
    "    dataEco['Kategorie'] = dataEco.apply(lambda x: x['FourthField'] if x['Firma']=='companyName3' else x['ThirdField'],axis=1)\n",
    "\n",
    "    dataEco['FirmaCode'] = dataEco.Firma.replace({'companyName1':'100', 'companyName2':'470', 'companyName3':'460', 'companyName4':'400'})\n",
    "    dataEco['KampagnenName'] = dataEco['KampagnenName'].str.lower()\n",
    "    dataEco['Besuche'] = np.nan\n",
    "    dataEco['Besucher'] = np.nan\n",
    "except Exception:\n",
    "    logging.exception(\"Problems Econda data cleaning 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T07:32:48.211677Z",
     "start_time": "2020-02-07T07:32:47.638543Z"
    }
   },
   "outputs": [],
   "source": [
    "# I perform here a groupby to sum up all the results belonging to the same \n",
    "# ('FirmaCode','KampagnenName','Land','Sprache') tuple. The reason is that\n",
    "# I want to sum up on things like different teaser, or whatever. Everything\n",
    "# belonging to this tuple should  be together.\n",
    "\n",
    "# We need to bring also the KPI Kategorie into the joining DataFrame even though\n",
    "# it is not something we can groupby on: in fact, it is lost in the dataEco_toJoin_a\n",
    "# In order to bring it to the next join I repeat the same groupby bringing only\n",
    "# Kategorie as KPI and taking the min (I could have also taken something else max, mean\n",
    "# or whatever)\n",
    "try:\n",
    "    dataEco_toJoin_a = dataEco.groupby(['FirmaCode','KampagnenName','Land','Sprache']).sum().reset_index()\n",
    "    dataEco_toJoin_b = dataEco.groupby(['FirmaCode','KampagnenName','Land','Sprache'])['Kategorie'].min().reset_index()\n",
    "    # I join the two above to get the final part to be further joined with the results from SFMC\n",
    "    dataEco_toJoin = pd.merge(dataEco_toJoin_a,dataEco_toJoin_b,on=['FirmaCode','KampagnenName','Land','Sprache'])\n",
    "except Exception:\n",
    "    logging.exception(\"Problems joining Econda data\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1872.22px",
    "left": "161px",
    "top": "109.72px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
