{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AT Internet Report\n",
    "\n",
    "This script loads the data for the report.  \n",
    "I get data from AT Internet and SalesForce MC, join the two over the composite  \n",
    "primary key (Firma, KampagnenName, Land, Sprache), removes from the database the entries  \n",
    "already present corresponding to the tuples in the DataFrame (the old ones with old values)  \n",
    "and replace them with the newly acquired data.  \n",
    "\n",
    "There is a small twist, described below: the web report and the rest api report are not able to  \n",
    "deliver `Quantity of purchased products`. So I had to use 2 similar report (here called `ROHDATEN_REPORT_FZ2`  \n",
    "and `ROHDATEN_REPORT_FZ2_ERGAENZUNG`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "import logging\n",
    "import pysftp\n",
    "import paramiko\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import email\n",
    "import smtplib\n",
    "\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Test EMail-Trigger & Get message\n",
    "if not sys.stdin.isatty():\n",
    "    msg = email.message_from_file(sys.stdin)\n",
    "    mailtrigger = True\n",
    "else:\n",
    "    mailtrigger = False\n",
    "\n",
    "\n",
    "cnopts = pysftp.CnOpts()\n",
    "cnopts.hostkeys = None   \n",
    "\n",
    "from time import asctime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# The logging class\n",
    "###########################################\n",
    "class TS(object):\n",
    "    def __repr__(self):\n",
    "        return strftime('%d.%m.%Y %H:%M:%S')\n",
    "ts = TS()\n",
    "\n",
    "logging.basicConfig(filename='LogFile.log',level=logging.DEBUG)\n",
    "logging.info(ts)\n",
    "logging.info('\\t Updating Log File')\n",
    "\n",
    "logging.debug(strftime('%d.%m.%Y %H:%M:%S'))\n",
    "logging.debug('\\n\\n#####################################')\n",
    "logging.debug('######### N E W   F I L E ###########')\n",
    "logging.debug('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calls\n",
    "\n",
    "Note that I need two api calls because of the issue with `produkte Stueckzahl verkauft` or `Quantity of purchased products`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Let's start with AT_Internet\n",
    "###########################################\n",
    "# \n",
    "# +++ THE NAME OF THE REPORT +++\n",
    "# ROHDATEN_REPORT_FZ2\n",
    "# &\n",
    "# ROHDATEN_REPORT_FZ2_ERGAENZUNG (for the single metric m_product_bought_quantity)\n",
    "# \n",
    "# +++ A TYPICAL REST QUERY +++\n",
    "# Call for Firma1\n",
    "# https://apirest.atinternet-solutions.com/data/v2/json/getData?&columns=\n",
    "# {d_site,cl_1234,cl_2345,cl_3456,m_visits,m_visitors_page,m_bounces,\n",
    "# m_nb_orders,m_sales,m_customers}&sort={-m_visits}&space={s:xxxxx}&period=\n",
    "# {R:{M:{start:'-5',end:'-1'}}}&max-results=50# \n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "# The REST API Request\n",
    "#############################################\n",
    "\n",
    "# To obtain also the number of bought articles (produkte Stueckzahl verkauft) I used \"Quantity of purchased products\"...)\n",
    "# and I had to \n",
    "# use it in a separate report \"ROHDATEN_REPORT_FZ1_ERGAENZUNG\". This metric did not work with the other metrics... \n",
    "# This new metric has the name \"m_product_bought_quantity\"\n",
    "# What I do is to prepare the two tables and then to match them on \n",
    "# Firma / Land / KampagnenName (sprache is always de!)\n",
    "\n",
    "try:\n",
    "    CodesATInternet = {'Firma1':{'KampagnenCode':'cl_xxx','SpaceCode':'{s:yyy}','KatCode':'cl_zzz','KanCode':'cl_ttt'},\n",
    "                      'Firma2':{'KampagnenCode':'cl_xxx2','SpaceCode':'{s:yyy2}','KatCode':'cl_zzz2','KanCode':'cl_ttt2'},\n",
    "                      'Firma3':{'KampagnenCode':'cl_xxx3','SpaceCode':'{s:yyy3}','KatCode':'cl_zzz3','KanCode':'cl_ttt3'}}\n",
    "    FirmaLand = ['Firma1','Firma2','Firma3']\n",
    "    url = 'https://apirest.atinternet-solutions.com/data/v2/json/getData' \n",
    "    headers = {'Authorization': 'Basic '+token}\n",
    "    #print(headers)\n",
    "    today = pd.datetime.today()\n",
    "    howManyMonths = 1\n",
    "    startDay = (today - pd.Timedelta(howManyMonths,'M')).strftime('%Y-%m-%d')\n",
    "    stopDay = (today - pd.Timedelta(1,'D')).strftime('%Y-%m-%d')\n",
    "    DataAll = pd.DataFrame()\n",
    "\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems while setting variables in ATInternet')\n",
    "\n",
    "for i in FirmaLand:\n",
    "    ####################################\n",
    "    # Getting the main bunch of KPIs\n",
    "    ####################################\n",
    "    try:\n",
    "        KampagnenCode = CodesATInternet[i]['KampagnenCode']\n",
    "        SpaceCode = CodesATInternet[i]['SpaceCode']\n",
    "        KanalCode = CodesATInternet[i]['KanCode']\n",
    "        KatCode = CodesATInternet[i]['KatCode']\n",
    "        #print(i,KampagnenCode,SpaceCode,KatCode,KanalCode)\n",
    "        payload =  {'columns': '{d_site,'+KanalCode+','+KatCode+','+KampagnenCode+',m_visits,m_visitors_page,m_bounces,m_nb_orders,m_sales,m_customers}', \n",
    "               'filter': '{d_source_campaign:{$lk:\\'Newsletter\\'}}',\n",
    "               'space': SpaceCode,\n",
    "                'period':'{D:{start:\\''+startDay+'\\',end:\\''+stopDay+'\\'}}',\n",
    "                    #'{R:{M:\\'-'+str(howManyMonths)+'\\'}}',\n",
    "                    #'{R:{M:{start:\\'-'+str(howManyMonths)+'\\',end:\\''+str(-1)+'\\'}}}',   #={R:{M:{start:'-6',end:'-1'}}}\n",
    "    #            'period':\"{D:{start:'2018-12-31',end:'2019-02-03'}}\",#'period':'{R:{M:\\'-'+str(howManyMonths)+'\\'}}',#\n",
    "               'max-results':'10000' }\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems while setting variables the loop ATInternet')\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url=url,headers=headers,params=payload)\n",
    "        #print(r.text)\n",
    "        jsonResponse = r.json()\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during the requests call in the loop ATInternet')\n",
    "    try:\n",
    "        # rename columns to be able to append the DataFrames\n",
    "        tempDF = pd.DataFrame(jsonResponse['DataFeed'][0]['Rows']).rename(columns={KampagnenCode:'KampNameATInternet'})\n",
    "        print(tempDF.shape)\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during DataFrame generation in the loop ATInternet')\n",
    "    \n",
    "    ########################################################################\n",
    "    # Getting the \"Produkte - Stueckzahl verkauft\" & Kategorie\n",
    "    ########################################################################\n",
    "    try:\n",
    "        payloadErg =  {'columns': '{d_site,'+KanalCode+','+KatCode+','+KampagnenCode+',m_product_bought_quantity}',\n",
    "                       'filter': '{d_source_campaign:{$lk:\\'Newsletter\\'}}',\n",
    "                       'space': SpaceCode,\n",
    "                       'period': '{D:{start:\\''+startDay+'\\',end:\\''+stopDay+'\\'}}',\n",
    "                       #'{R:{M:\\'-'+str(howManyMonths)+'\\'}}',   \n",
    "                       #'{R:{M:{start:\\'-'+str(howManyMonths)+'\\',end:\\''+str(-1)+'\\'}}}',  #={R:{M:{start:'-6',end:'-1'}}}\n",
    "            #            'period':\"{D:{start:'2018-12-31',end:'2019-02-03'}}\",#'period':'{R:{M:\\'-'+str(howManyMonths)+'\\'}}'\n",
    "                       'max-results':'10000' }\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems while setting variables the Ergaenzung loop ATInternet')\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url=url,headers=headers,params=payloadErg)\n",
    "        jsonResponse = r.json()\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during the requests call in the Ergaenzung loop ATInternet')\n",
    "    try:\n",
    "        # rename columns to be able to append the DataFrames\n",
    "        tempDF_ergaenzung = pd.DataFrame(jsonResponse['DataFeed'][0]['Rows']).rename(columns={KampagnenCode:'KampNameATInternet'})\n",
    "        print(tempDF_ergaenzung.shape)\n",
    "\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during DataFrame Ergaenzung generation in the loop ATInternet')\n",
    "\n",
    "    try:    \n",
    "        # Outer join because I want to catch also the case in which, for example, there is no information about \n",
    "        # the amount of bought articles but indeed info about the rest. I want to nevertheless maintain this entry\n",
    "        # even though with nan in the field for the m_product_bought_quantity\n",
    "        # I use also Katcode to merge to consider all the impostant dimensions, I get otherwise \n",
    "        # unwanted molitplication of entries\n",
    "        tempMerged = (pd.merge(tempDF,tempDF_ergaenzung,on=['d_site','KampNameATInternet',KatCode], how='outer')\n",
    "                      .rename(columns={KatCode:'Kategorie'}))\n",
    "        #print(tempMerged)\n",
    "        DataAll = DataAll.append(tempMerged,ignore_index=True,sort=True)\n",
    "\n",
    "    except:\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during tempMerged joining or appending to DataAll')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the two reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    # Splitting into Firma Land\n",
    "    DataAll['Firma'] = DataAll.d_site.str.split().apply(lambda x:x[0].lower())\n",
    "    DataAll['Land'] = DataAll.d_site.str.split().apply(lambda x:x[1].lower())\n",
    "    DataAll['Sprache'] = 'de'\n",
    "\n",
    "\n",
    "    DataAll.rename(columns={'m_bounces':'Bounces','m_customers':'Kunden',\n",
    "                            'm_nb_orders':'Bestellungen','m_sales':'Umsatz',\n",
    "                            'm_visits':'Besuche','m_visitors_page':'Besucher',\n",
    "                            'm_product_bought_quantity':'Produkte - Stueckzahl verkauft'}, inplace=True)\n",
    "    DataAll['FirmaCode'] = DataAll.Firma.replace({'impressionen':'550', 'conleys':'551'})\n",
    "    DataAll['Land'] = DataAll.Land.replace({'de':'004', 'at':'038', 'ch':'039'})\n",
    "    DataAllFinal = DataAll.loc[:,['KampNameATInternet','Kategorie','FirmaCode','Land','Sprache','Bounces','Kunden',\n",
    "                               'Bestellungen',\n",
    "                               'Umsatz','Besuche','Besucher',\n",
    "                               'Produkte - Stueckzahl verkauft']]\n",
    "    DataAllFinal['KampNameATInternet'] = DataAllFinal['KampNameATInternet'].str.lower()\n",
    "    DataAllFinal['Besuche_unique'] = np.nan\n",
    "    DataAllFinal['Besucher_unique'] = np.nan\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+' problems during DataAll or DataAllATInt preparation')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Salesforce\n",
    "\n",
    "We cannot use rest api, unfortunately. So I let SFMC automatically create a report  \n",
    "that is saved on SFMC server. Here below, I access the remotr directory and  \n",
    "download the latest report (actually, the lates file beginning with Rohdaten_Export_KMT_Report)  \n",
    "We work without cache: we immediately transform the ftp file in a   \n",
    "DataFrame without intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Now it's SFMC's turn\n",
    "###########################################\n",
    "\n",
    "\n",
    "try:\n",
    "    client = paramiko.SSHClient()\n",
    "    client.load_host_keys(os.path.expanduser('../../known_hosts'))\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(hostname='salesforce.server.de',username='12345678',password='password')\n",
    "    client.close()\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Problems with the paramiko connection')\n",
    "\n",
    "try:\n",
    "    with pysftp.Connection(host='salesforce.server.de', username='12345678', password='password') as sftp:\n",
    "        sftp.chdir('reports')\n",
    "        Lista = sftp.listdir_attr()\n",
    "        FileList = pd.DataFrame([(attr.filename,attr.st_mtime) for attr in Lista],columns=['FileName','Mod_Time'])\n",
    "        DasFile = (FileList.loc[FileList.FileName.str.contains('Rohdaten_Export_KMT_Report'),:]\n",
    "                       .sort_values(by='Mod_Time',ascending=False)[:1]\n",
    "                       .loc[:,'FileName']\n",
    "                       .tolist()[0])\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': We are using the file:'+DasFile)\n",
    "        \n",
    "        whichColsSFMC = ['Versanddatum','Mitteilungs-ID','Geschäftseinheitskonto','Land','Sprache','E-Mail-Name',\n",
    "                         'Nachrichtentyp','Desktop~SENDUNGEN','Desktop~Zustellungen',\n",
    "                         'Desktop~Öffnungen unique','Mobile~Öffnungen unique','Desktop~GEÖFFNET','Mobile~GEÖFFNET',\n",
    "                         'Desktop~Einmaliger Klick',\n",
    "                         'Mobile~Einmaliger Klick','Desktop~Klicks','Mobile~Klicks','Desktop~Bounces','Desktop~Bounce – blockieren',\n",
    "                         'Desktop~Bounce – weich','Desktop~Bounce – hart','Desktop~Bounce – technisch','Desktop~Bounce – unbekannt',\n",
    "                         'Desktop~Abmeldungen netto','Desktop~Beschwerden','Versanddatum']\n",
    "\n",
    "        dataSFMC = (pd.read_csv(sftp.open(DasFile),usecols=whichColsSFMC,\n",
    "                               thousands='.',dtype={'Land': 'object','Mitteilungs-ID':'object'})\n",
    "                    .rename(columns={'Desktop~SENDUNGEN':'VersendeteEmails','Geschäftseinheitskonto':'Firma',\n",
    "                                     'Desktop~Zustellungen':'Zustellungen',\n",
    "                                     'Desktop~Öffnungen unique':'OeffnungenUnique_Desktop',\n",
    "                                     'Mobile~Öffnungen unique':'OeffnungenUnique_Mobile',\n",
    "                                     'Desktop~GEÖFFNET':'GeoeffneteMails_Desktop',\n",
    "                                     'Mobile~GEÖFFNET':'GeoeffneteMails_Mobile',\n",
    "                                     'Desktop~Einmaliger Klick':'ClicksUnique_Desktop',\n",
    "                                     'Mobile~Einmaliger Klick':'ClicksUnique_Mobile',\n",
    "                                     'Desktop~Klicks':'Clicks_Desktop',\n",
    "                                     'Mobile~Klicks':'Clicks_Mobile',\n",
    "                                     'Desktop~Bounces':'BouncesGesamt',\n",
    "                                     'Desktop~Bounce – blockieren':'BouncesBlockiert',\n",
    "                                     'Desktop~Bounce – weich':'BouncesWeich',\n",
    "                                     'Desktop~Bounce – hart':'BouncesHart',\n",
    "                                     'Desktop~Bounce – technisch':'BouncesTechnisch',\n",
    "                                     'Desktop~Bounce – unbekannt':'BouncesUnbekannt',\n",
    "                                     'Desktop~Abmeldungen netto':'AbmeldungenNetto',\n",
    "                                     'Desktop~Beschwerden':'Beschwerden',\n",
    "                                     'E-Mail-Name':'KampagnenNameSF','Mitteilungs-ID':'JobID'}))\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Importing the ftp file')\n",
    "        dataSFMC['Versanddatum'] = pd.to_datetime(dataSFMC.Versanddatum)\n",
    "#         dataSFMC['Versanddatum'] = dataSFMC['Versanddatum'].apply(lambda x: x.strftime('%Y-%m-%d'))# %H:%M:%S\n",
    "        dataSFMC['Sprache'] = dataSFMC['Sprache'].str.lower()\n",
    "        dataSFMC['FirmaCode'] = dataSFMC.Firma.str.lower().replace({'Firma1':'100', 'Firma2':'470', 'Firma2':'460'})\n",
    "        dataSFMC['KampagnenNameSF'] = dataSFMC['KampagnenNameSF'].str.lower()\n",
    "        logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Ready!')\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Problems with the ftp connection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSFMC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# We have both DataFrames, let's prepare them\n",
    "##############################################\n",
    "# First ATInternet\n",
    "###################\n",
    "try:\n",
    "    DataAllATInt_toJoin_a = DataAllFinal.groupby(['FirmaCode','KampNameATInternet','Land','Sprache']).sum().reset_index()\n",
    "    DataAllATInt_toJoin_b = DataAllFinal.groupby(['FirmaCode','KampNameATInternet','Land','Sprache'])['Kategorie'].min().reset_index()\n",
    "    DataAllATInt_toJoin = pd.merge(DataAllATInt_toJoin_a,DataAllATInt_toJoin_b,on=['FirmaCode','KampNameATInternet','Land','Sprache'])\n",
    "#     print(DataAllATInt_toJoin.columns)\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while creating DataAllATInt_toJoin')\n",
    "\n",
    "###################\n",
    "# Now SFMC\n",
    "###################\n",
    "\n",
    "try:    \n",
    "    dataSFMC_toJoin_a = dataSFMC.groupby(['FirmaCode','KampagnenNameSF','Land','Sprache']).sum().reset_index()\n",
    "    dataSFMC_toJoin_b = dataSFMC.groupby(['FirmaCode','KampagnenNameSF','Land','Sprache'])['Versanddatum','Nachrichtentyp'].min().reset_index()\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while creating dataSFMC_toJoin_a and dataSFMC_toJoin_b')\n",
    "\n",
    "    \n",
    "    \n",
    "try:    \n",
    "    # I use these two steps to put also the oldest date in the dataframe, in the case the same campaign was sent on two \n",
    "    # different days. This happened a couple of times, for example albamoda nikolaus mail.\n",
    "    # I need the date to make the aggregation work simpler in Jedox\n",
    "    dataSFMC_toJoin = pd.merge(dataSFMC_toJoin_a,dataSFMC_toJoin_b,on=['FirmaCode','KampagnenNameSF','Land','Sprache'])\n",
    "    dataSFMC_toJoin['Jahr'] = dataSFMC_toJoin.Versanddatum.dt.year\n",
    "    dataSFMC_toJoin['Monat'] = dataSFMC_toJoin.Versanddatum.dt.month\n",
    "    dataSFMC_toJoin['Woche'] = dataSFMC_toJoin.Versanddatum.dt.week\n",
    "#     print(dataSFMC_toJoin.columns)\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while creating dataSFMC_toJoin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the data from Salesforce with those from ATInternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FirmaCode', 'KampagnenName', 'Land', 'Sprache', 'Bounces', 'Kunden',\n",
      "       'Bestellungen', 'Umsatz', 'Besuche', 'Besucher',\n",
      "       'Produkte - Stueckzahl verkauft', 'Besuche_unique', 'Besucher_unique',\n",
      "       'Kategorie', 'VersendeteEmails', 'Zustellungen', 'BouncesGesamt',\n",
      "       'BouncesBlockiert', 'BouncesHart', 'BouncesWeich', 'BouncesTechnisch',\n",
      "       'BouncesUnbekannt', 'OeffnungenUnique_Desktop',\n",
      "       'GeoeffneteMails_Desktop', 'ClicksUnique_Desktop', 'Clicks_Desktop',\n",
      "       'AbmeldungenNetto', 'Beschwerden', 'OeffnungenUnique_Mobile',\n",
      "       'GeoeffneteMails_Mobile', 'ClicksUnique_Mobile', 'Clicks_Mobile',\n",
      "       'Versanddatum', 'Nachrichtentyp', 'Jahr', 'Monat', 'Woche', 'Audit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Let's JOIN!\n",
    "###################\n",
    "try:\n",
    "    ATIntSFMC = (pd.merge(DataAllATInt_toJoin,dataSFMC_toJoin,left_on=['FirmaCode','KampNameATInternet','Land','Sprache'],right_on=['FirmaCode','KampagnenNameSF','Land','Sprache'])\n",
    "                .rename(columns={'KampNameATInternet':'KampagnenName'}))\n",
    "    ATIntSFMC = ATIntSFMC.drop('KampagnenNameSF',axis=1)\n",
    "    ATIntSFMC['Versanddatum'] = ATIntSFMC.Versanddatum.dt.strftime('%Y-%m-%d')\n",
    "    ATIntSFMC.loc[:,'Audit'] = pd.datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     print(ATIntSFMC.columns)\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while creating EcoSFMC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into the PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    engine = create_engine('postgresql+psycopg2://user-name:password@Server/Database', echo=False)\n",
    "\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while creating engine')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First we completely delete the entries we want to replace with more recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for n,row in enumerate(zip(ATIntSFMC.FirmaCode,ATIntSFMC.KampagnenName,ATIntSFMC.Land,ATIntSFMC.Sprache)):\n",
    "        sqlDelete = ''' DELETE FROM \"Production\".\"AT_Eco_SFMC\" WHERE '''\n",
    "        sqlDelete += '''\"FirmaCode\"='{}' AND \"KampagnenName\"='{}' AND \"Land\"='{}' AND \"Sprache\"='{}' '''.format(row[0],row[1],row[2],row[3])\n",
    "        engine.execute(sqlDelete)\n",
    "except:\n",
    "    logging.debug(strftime('%d.%m.%Y %H:%M:%S')+': Failed while deleting old entries')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we upload the recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irows in range(ATIntSFMC.shape[0]):\n",
    "    string = 'INSERT INTO \"Production\".\"AT_Eco_SFMC\" ('\n",
    "    for n,icol in enumerate(ATIntSFMC.columns.values):\n",
    "        if n==ATIntSFMC.columns.values.shape[0]-1:\n",
    "            string += '\"'+icol+'\"'+')'\n",
    "        else:\n",
    "            string += '\"'+icol+'\"'+','\n",
    "\n",
    "    string += ' VALUES('\n",
    "    for n,icol in enumerate(ATIntSFMC.columns.values):\n",
    "        if type(ATIntSFMC.iloc[0,n])==str:\n",
    "            if n==ATIntSFMC.columns.values.shape[0]-1:\n",
    "                string += '\\''+str(ATIntSFMC.iloc[irows,n]) + '\\''+')'\n",
    "            else:\n",
    "                string += '\\''+str(ATIntSFMC.iloc[irows,n]) + '\\''+','\n",
    "        else:\n",
    "            if n==ATIntSFMC.columns.values.shape[0]-1:\n",
    "                string += str(ATIntSFMC.iloc[irows,n]) +')'\n",
    "            else:\n",
    "                string += str(ATIntSFMC.iloc[irows,n])+','\n",
    "\n",
    "    string +=';'\n",
    "    engine.execute(string) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT INTO \"Production\".\"AT_Eco_SFMC\" (\"FirmaCode\",\"KampagnenName\",\"Land\",\"Sprache\",\"Bounces\",\"Kunden\",\"Bestellungen\",\"Umsatz\",\"Besuche\",\"Besucher\",\"Produkte - Stueckzahl verkauft\",\"Besuche_unique\",\"Besucher_unique\",\"Kategorie\",\"VersendeteEmails\",\"Zustellungen\",\"BouncesGesamt\",\"BouncesBlockiert\",\"BouncesHart\",\"BouncesWeich\",\"BouncesTechnisch\",\"BouncesUnbekannt\",\"OeffnungenUnique_Desktop\",\"GeoeffneteMails_Desktop\",\"ClicksUnique_Desktop\",\"Clicks_Desktop\",\"AbmeldungenNetto\",\"Beschwerden\",\"OeffnungenUnique_Mobile\",\"GeoeffneteMails_Mobile\",\"ClicksUnique_Mobile\",\"Clicks_Mobile\",\"Versanddatum\",\"Nachrichtentyp\",\"Jahr\",\"Monat\",\"Woche\",\"Audit\") VALUES(\\'551\\',\\'2019-03-10_kw10_so_maritimeliebe\\',\\'039\\',\\'de\\',90,9,15,4623.41,256,231,47,0.0,0.0,\\'Thema_F\\',12401,12383,18,1,1,5,0,11,430,641,92,157,14,0,1286,1647,196,278,\\'2019-03-10\\',\\'Job Send\\',2019,3,10,\\'2019-03-11 08:32:04\\');'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nmsg = MIMEText('Task Finished.')\n",
    "if mailtrigger:\n",
    "    nmsg['To'] = msg.get('From')\n",
    "    nmsg['Subject'] = 'AW:'+msg.get('Subject')\n",
    "else:\n",
    "    nmsg['To'] = 'my.name@company.de'\n",
    "    nmsg['Subject'] = 'Salesfore Report'\n",
    "nmsg['From'] = 'automatic@report.company.de'\n",
    "s = smtplib.SMTP('localhost')\n",
    "s.sendmail('automatic@report.company.de', [nmsg['To']], nmsg.as_string())\n",
    "s.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
